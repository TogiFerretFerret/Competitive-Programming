Code A:
```
/**
 * E. Remove at the lowest cost
 *
 * Approach:
 * 1. Groups & SuperGroups: 
 *    - Consecutive identical elements form Basic Groups.
 *    - Basic Groups separated by valleys of strictly smaller elements are conceptually neighbors in the 
 *      same component (connected). We merge such groups into SuperGroups (SGs).
 *      Detection: Identify NGL (Nearest Strictly Greater Left) and NGR. If for a valley range [i..j], 
 *      val(NGL) == val(NGR), then groups NGL and NGR are part of the same SG.
 *      Implementation: Iterate Basic Groups. If Group `i` has neighbors L, R such that `val[i] < val[L]` 
 *      and `val[i] < val[R]`, and `val[L] == val[R]`, union `L` and `R`.
 *
 * 2. Hierarchy (DAG):
 *    - Form a Directed Acyclic Graph where larger value SGs act as parents to smaller value SGs.
 *    - "Peaks" are SGs with no parents (top of the value hierarchy).
 *    - "Valleys" are SGs with one or more parents.
 *
 * 3. Cost Calculation Formula:
 *    - Let `M = MinCost(SuperGroup)`.
 *    - Let `B` be the "Effective Boundary" offered by parents. `B = min(ParentEffective...)`.
 *      For Peaks, `B` is undefined initially, but peaks form a cluster that bounds itself.
 *    - The effective elimination cost for every element in a SuperGroup is `E = min(M, B)`.
 *    - Total Cost contribution for a SG: `Size * E`.
 *    - SG effectively offers `E` to its own children.
 *
 * 4. Handling Peaks Globally:
 *    - Peak SuperGroups effectively form a top-level cluster that must eliminate itself down to 1 element.
 *    - The boundary `B` for ANY Peak is effectively `GlobalMinPeak` (M*). 
 *    - Why? The cheapest peak survivor can eliminate the others.
 *    - So `E_peak = min(M_peak, M*) = M*`.
 *    - Cost of Peaks: `Sum(Size_i * M*)` across all peaks.
 *    - Correction: We remove all elements except one global survivor. Since cost `E` counts full removal, 
 *      we subtract `M*` once to spare the final survivor.
 *      Peak Contribution = `(TotalPeakElems - 1) * GlobalMinPeak`.
 *
 * 5. Updates:
 *    - Costs zero out dynamically. This reduces `M` for a SG.
 *    - Updates propagate down the DAG: SGs recompute `E` based on new `M` and new Parent `B`.
 *    - If `E` (offer to children) changes, children are queued for update.
 *    - Total complexity O(N log N) (bounded by sum of edges in DAG which is O(N), plus set ops).
 */

#include <iostream>
#include <vector>
#include <algorithm>
#include <set>
#include <stack>
#include <numeric>

using namespace std;

const long long INF = 2e18; 

struct DSU {
    vector<int> p;
    DSU(int n) { p.resize(n); iota(p.begin(), p.end(), 0); }
    int find(int x) { return p[x] == x ? x : p[x] = find(p[x]); }
    void join(int a, int b) {
        a = find(a); b = find(b);
        if (a != b) p[b] = a; 
    }
};

struct SuperGroup {
    int id;
    int size = 0;
    multiset<int> costs; 
    vector<int> parents; // Strictly greater parents
    
    // Cached values
    int min_c = 0;
    long long term_valley = 0; // Contribution to answer (if valley)
    
    // For sorting: strictly descending order of value `a` ensures parents processed before children
    int rep_val = 0; 
    bool is_peak = false;
    
    int get_min() {
        if (costs.empty()) return 2e9 + 7;
        return *costs.begin();
    }
    
    void refresh() {
        min_c = get_min();
    }
};

int n;
vector<int> a, init_c, p_ops;
vector<SuperGroup> sgs;
vector<int> elem_sg; // Map element index to SuperGroup
vector<vector<int>> children; // Graph edges (Parent -> Children)
vector<int> sg_eff_offer;     // What this SG offers as boundary to children

// State Tracking
long long total_valley = 0; // Sum of (Size * E) for all Valleys
long long total_peak_elems = 0;
multiset<int> peak_mins; 

long long get_peak_part() {
    if (total_peak_elems == 0) return 0;
    // We treat all Peak elements as a pool. They remove each other until 1 remains.
    // The cost unit is the global minimum of the current peak set.
    // Cost = (N_Peaks - 1) * GlobalMin
    int m = (peak_mins.empty() ? 0 : *peak_mins.begin());
    return (total_peak_elems - 1) * (long long)m;
}

// Recompute state for SG u. Returns true if its output `E` changes.
bool relax(int u) {
    SuperGroup &g = sgs[u];
    
    if (g.is_peak) {
        // Peaks Logic is handled by `get_peak_part`.
        // However, Peaks MUST offer a boundary to their valley children.
        // A Peak offers its own internal Min as boundary.
        int new_offer = g.min_c;
        if (new_offer != sg_eff_offer[u]) {
            sg_eff_offer[u] = new_offer;
            return true;
        }
        return false;
    }
    
    // Valley Logic:
    // 1. Determine best boundary offered by any parent
    int bound = 2e9 + 7;
    for (int p : g.parents) {
        bound = min(bound, sg_eff_offer[p]);
    }
    
    // 2. Determine Effective Elimination cost
    // We use min(Internal Min, Parent Boundary)
    int E = min(g.min_c, bound);
    long long new_cost = (long long)g.size * E;
    
    bool changed = false;
    
    // Update Global Sum (Delta update)
    if (new_cost != g.term_valley) {
        total_valley -= g.term_valley;
        g.term_valley = new_cost;
        total_valley += g.term_valley;
    }
    
    // Update Offer to children
    if (E != sg_eff_offer[u]) {
        sg_eff_offer[u] = E;
        changed = true;
    }
    return changed;
}

void solve() {
    if (!(cin >> n)) return;
    
    a.resize(n); init_c.resize(n); p_ops.resize(n);
    for(int i=0; i<n; ++i) cin >> a[i];
    for(int i=0; i<n; ++i) cin >> init_c[i];
    for(int i=0; i<n; ++i) { cin >> p_ops[i]; p_ops[i]--; }
    
    // 1. Identify Basic Groups (BG) of consecutive equal elements
    vector<int> bg_id(n);
    vector<int> bg_vals;
    int bg_cnt = 0;
    if(n > 0) {
        int l = 0;
        for(int i=1; i<n; ++i) {
            if(a[i] != a[i-1]) {
                bg_vals.push_back(a[l]);
                for(int k=l; k<i; ++k) bg_id[k] = bg_cnt;
                bg_cnt++;
                l = i;
            }
        }
        bg_vals.push_back(a[l]);
        for(int k=l; k<n; ++k) bg_id[k] = bg_cnt;
        bg_cnt++;
    }
    
    // 2. Identify NGL/NGR for Basic Groups to detect "Connected" Valleys
    vector<int> ngl(bg_cnt, -1), ngr(bg_cnt, -1);
    stack<int> s;
    for(int i=0; i<bg_cnt; ++i) {
        while(!s.empty() && bg_vals[s.top()] <= bg_vals[i]) s.pop();
        if(!s.empty()) ngl[i] = s.top();
        s.push(i);
    }
    while(!s.empty()) s.pop();
    for(int i=bg_cnt-1; i>=0; --i) {
        while(!s.empty() && bg_vals[s.top()] <= bg_vals[i]) s.pop();
        if(!s.empty()) ngr[i] = s.top();
        s.push(i);
    }
    
    // 3. Union Groups into SuperGroups (SGs)
    // Connect groups L and R if they border the same valley group `i`
    // i.e., group `i` is strictly smaller than L and R, and val(L) == val(R).
    // Here we iterate all groups and use NGL/NGR info directly.
    DSU dsu(bg_cnt);
    for(int i=0; i<bg_cnt; ++i) {
        if(ngl[i] != -1 && ngr[i] != -1 && bg_vals[ngl[i]] == bg_vals[ngr[i]]) {
            dsu.join(ngl[i], ngr[i]);
        }
    }
    
    // 4. Instantiate SuperGroups
    vector<int> map_sg(bg_cnt, -1); // Map BG -> SG index
    int sg_sz = 0;
    for(int i=0; i<bg_cnt; ++i) {
        int r = dsu.find(i);
        if(map_sg[r] == -1) map_sg[r] = sg_sz++;
    }
    
    sgs.assign(sg_sz, {});
    for(int i=0; i<sg_sz; ++i) sgs[i].id = i;
    elem_sg.resize(n);
    
    // Populate elements
    for(int i=0; i<n; ++i) {
        int r = dsu.find(bg_id[i]);
        int u = map_sg[r];
        elem_sg[i] = u;
        sgs[u].costs.insert(init_c[i]);
        sgs[u].size++;
        sgs[u].rep_val = a[i]; // Store 'value' for sort
    }
    
    // 5. Build SG Hierarchy (Parents)
    // Parent P of SG U exists if U has NGL/NGR pointing to P.
    for(int i=0; i<bg_cnt; ++i) {
        int u = map_sg[dsu.find(i)];
        if(ngl[i] != -1) {
            int p = map_sg[dsu.find(ngl[i])];
            if(u != p) sgs[u].parents.push_back(p);
        }
        if(ngr[i] != -1) {
            int p = map_sg[dsu.find(ngr[i])];
            if(u != p) sgs[u].parents.push_back(p);
        }
    }
    
    // 6. Dedup and Init Logic
    children.assign(sg_sz, {});
    peak_mins.clear();
    total_valley = 0;
    total_peak_elems = 0;
    sg_eff_offer.assign(sg_sz, 2e9+7);

    for(int i=0; i<sg_sz; ++i) {
        sort(sgs[i].parents.begin(), sgs[i].parents.end());
        sgs[i].parents.erase(unique(sgs[i].parents.begin(), sgs[i].parents.end()), sgs[i].parents.end());
        
        if(sgs[i].parents.empty()) {
            sgs[i].is_peak = true;
            total_peak_elems += sgs[i].size;
        } else {
            // Build Inverse graph for updates
            for(int p : sgs[i].parents) children[p].push_back(i);
        }
        
        sgs[i].refresh();
        if(sgs[i].is_peak) peak_mins.insert(sgs[i].min_c);
    }
    
    // 7. Initial Propagation (Topological by Value: High -> Low)
    // Larger values (parents) determine bounds for smaller values (valleys).
    vector<int> ord(sg_sz);
    iota(ord.begin(), ord.end(), 0);
    sort(ord.begin(), ord.end(), [&](int x, int y){
        return sgs[x].rep_val > sgs[y].rep_val;
    });
    
    for(int u : ord) relax(u);
    
    // Output Initial
    cout << total_valley + get_peak_part() << " ";
    
    // 8. Process Updates (Zeroing operations)
    vector<int> q; q.reserve(sg_sz); // For propagating updates
    
    for(int k=0; k<n; ++k) {
        int idx = p_ops[k];
        int u = elem_sg[idx];
        
        // Remove contribution of modified SG from aggregates temporarily
        if(sgs[u].is_peak) {
            peak_mins.erase(peak_mins.find(sgs[u].min_c));
        }
        // Valleys updated via 'relax', no pre-removal from global total required since relax uses delta
        
        // Modify Costs
        sgs[u].costs.erase(sgs[u].costs.find(init_c[idx]));
        sgs[u].costs.insert(0);
        sgs[u].refresh();
        
        if(sgs[u].is_peak) {
            peak_mins.insert(sgs[u].min_c);
        }
        
        // Propagate down children if `Offer` changes
        if(relax(u)) {
            q.clear();
            for(int v : children[u]) q.push_back(v);
            
            int h = 0;
            while(h < (int)q.size()) {
                int cur = q[h++];
                if(relax(cur)) {
                    for(int nxt : children[cur]) q.push_back(nxt);
                }
            }
        }
        
        cout << total_valley + get_peak_part() << " ";
    }
    cout << "\n";
}

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);
    int t;
    if(cin >> t) while(t--) solve();
    return 0;
}

```

Code B:
```
// Problem: E. Remove at the lowest cost
// Judge: Codeforces
// URL: https://codeforces.com/contest/2176/problem/E
// Memory Limit: 256 MB
// Time Limit: 3000 ms
#include <bits/stdc++.h>
using namespace std;
typedef long long ll;
static const uint64_t CHRONO_RANDOM = chrono::steady_clock::now().time_since_epoch().count();
static const uint64_t PIDRNDP = (uint64_t)(getpid())*0xbffbffbffULL;
static mt19937_64 PIDRNG(PIDRNDP);
static const uint64_t PIDRND = PIDRNG();
static const uint64_t FIXED_RANDOM = CHRONO_RANDOM ^ PIDRND;
struct CHASH {
    template <typename T> size_t operator()(const T& x) const {
        return hash<T>{}(x) ^ FIXED_RANDOM;
    }
    template <typename T1, typename T2> size_t operator()(const pair<T1, T2>& x) const {
        return (*this)(x.first) ^ ((*this)(x.second) + 0x9e3779b9 + (x.first << 6) + (x.first >> 2));
    }
};
template<class T, class U> istream& operator>>(istream& i, pair<T, U>& p) { return i >> p.first >> p.second; }
template<class T, class U> ostream& operator<<(ostream& o, const pair<T, U>& p) { return o << p.first << " " << p.second; }
template<class T> istream& operator>>(istream& i, vector<T>& v) { for(auto& x : v) i >> x; return i; }
template<class T> ostream& operator<<(ostream& o, const vector<T>& v) { for(int i=0; i<v.size(); ++i) o << v[i] << (i==v.size()-1?"":" "); return o; }
#define m1(x) template<class T, class... U> void x(T&& a, U&&... b)
#define m2(x) (int[]){(x forward<U>(b),0)...}
template<typename T1,typename T2> using hashmap=unordered_map<T1,T2,CHASH>;
template<typename TM> using matrix=vector<vector<TM>>;
using graph=matrix<int>;
template<typename TM> using tensor=vector<matrix<TM>>;
template<typename TM> using hypermatrix=vector<tensor<TM>>;
template<typename TM, TM Val = TM(), typename... Args> auto make(size_t first, Args... args){
    if constexpr(sizeof...(args) == 0){
        return vector<TM>(first, Val);
    } else {
        return vector<decltype(make<TM, Val>(args...))>(first, make<TM, Val>(args...));
    }
}
#define all(x) (x).begin(),(x).end()
#define forn(i,n) for(int i=0;i<(n);++i)
#define f0rn(v,s,e) for(int v=(s);v>(e);--v)
#define fOrn(v,s,e) for(int v=(s);v<(e);++v)
#define INTERACTIVE false
#ifndef LOCAL_JUDGE
#define FILEMODE false
#define FILENAME "pname"
#endif
#if INTERACTIVE
m1(out) { cout << forward<T>(a);  m2(cout << " " <<); cout << endl; }//softmod for interactive
m1(debug) { cerr << forward<T>(a);  m2(cerr << " " <<); cerr << "\n"; }
m1(in) { cin >> forward<T>(a); m2(cin >>); }
#else
m1(out) { cout << forward<T>(a);  m2(cout << " " <<); cout << "\n"; }//softmod for interactive
m1(debug) { cerr << forward<T>(a);  m2(cerr << " " <<); cerr << "\n"; }
m1(in) { cin >> forward<T>(a); m2(cin >>); }
#endif
#define MULTITEST true
#define pb push_back
void solve(){

}
int main(){
    if(!INTERACTIVE)cin.tie(0)->sync_with_stdio(0);
    #ifndef LOCAL_JUDGE
    #if FILEMODE
    freopen(FILENAME".in","r",stdin);
    freopen(FILENAME".out","w",stdout);
    #endif
    #endif
    int t=1;
    if (MULTITEST) cin>>t;
    forn(i,t)solve();
}
````
